---
title: "Assignment C"
subtitle: "Diagnostics & Remedial Measures"
format:
  html:
    toc: true
self-contained: true
link-external-newwindow: true
editor_options: 
  chunk_output_type: console
---

## Instructions {.unnumbered}

1.  You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.

2.  Make R code chunks to insert code and type your answer outside the code chunks. Ensure that the solution is written neatly enough to understand and grade.

3.  Render the file as HTML to submit. For theoretical questions, you can either type the answer and include the solutions in this file, or write the solution on paper, scan and submit separately.

4.  The assignment is worth 100 points, and is due on **22nd October 2023 at 11:59 pm**.

5.  **Five points are properly formatting the assignment**. The breakdown is as follows:

-   Must be an HTML file rendered using Quarto (the theory part may be scanned and submitted separately) (2 pts).
-   There aren't excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren't long printouts of which iteration a loop is on, there aren't long sections of commented-out code, etc.). There is no piece of unnecessary / redundant code, and no unnecessary / redundant text (1 pt)
-   Final answers of each question are written clearly (1 pt).
-   The proofs are legible, and clearly written with reasoning provided for every step. They are easy to follow and understand (1 pt)


All question are based on the normal linear regression model below, unless otherwise stated:

$Y_i = \beta_0 + \beta_1X_i + \epsilon_i, i = 1,...,n$, where $\epsilon \sim N(0, \sigma^2)...(1)$

## Real estate sales

Read the file *real_estate_sales.txt*. 

### 

Develop a linear regression model to predict `price` of a house based on `square_feet` *(floor area of the house)*. Check the following model assumptions using diagnostic plots:

1. Linear relationship

2. Homoscedasticity

3. Normal distribution of errors

For each of the above assumption, comment if it is appears to be satisfied or violated based on the plots.

*(2 + 2 + 2 = 6 points)*

### 
Consider performing the statistical test to check the linear relationship assumption. What condition must be satisfied by the data for the test to be performed? Show that the condition is satisfied by this data.

*(1 + 2 = 3 points)*

### 
Perform the statistical test to check the linear relationship assumption. What is your conclusion?

*(2 points)*

### 
Check assumptions (2) and (3) in the first question with statistical tests, and mention your conclusion.

*(2 + 2 = 4 points)*

### 

Use the Box-Cox procedure to identify the appropriate transformation of the regression model developed in the first question. Write the transformed model equation.

*(3 + 2 = 5 points)*

### 
Check all the 3 model assumptions mentioned in the first question for the transformed model. Use both diagnostic plots and statistical tests. Mention your comments based on the plots and conclusions based on the tests.

*(2 + 2 + 2 = 6 points)*

### 
Is the transformed model better than the original model with respect to the model assumptions? Comment based on the tests in the previous question.

*(2 points)*

### 
If the linearity assumption is still not satisfied in the transformed model, 

a. Propose another transformation based on the diagnostic plot(s) plotted in the previous question. 

b. Write the transformed model equation. 

c. Show that the transformed model satisfied the linearity assumption based on the statistical test, if probability of type I error is considered as 1\%. 

d. Also make the diagnostic plot for the transformed model to show that it satisfies the linearity assumption

*(2 + 2 + 2 + 2 = 8 points)*

### 
Does the transformed model developed in the previous question satisfy the normality and constant variance assumptions? Verify based on diagnostic plots and statistical tests.

*(2 + 2 = 4 points)*

### 
Plot all the three models - the original model, the boxcox transformed model, and the final model over a scatterplot of `price` vs `square_feet`. Which model seems to have the best fit? Also report the R-squared of all the 3 models.

*(1 + 3 + 1 + 3 = 8 points)*

## 

The dataset *infmort.csv* gives the infant mortality of different countries in the world. The column `mortality` contains the infant mortality in deaths per 1000 births. 

### 
Read the dataset. There are 4 observations that have missing values. Remove those observations from the dataset.

You may use the R function `complete.cases()`.

*(2 points)*

###

Over the scatterplot of `mortality` against `income`, plot the regression model predicting `mortality` based on `income`. Also report the $R^2$ for this model.

*(2 + 1 = 3 points)*

###
Are there outlying observations in the data with respect to the model developed in the previous question? How many? Consider observations having a magnitude of standardized residual more than 5 as outliers.

*(2 points)*

### 
Based on the plot, propose a transformation for `income`. Justify the transformations. Write the equation of the transformed model and report the updated $R^2$.  

*(2 + 2 + 1 + 1 = 6 points)*

Almost all the data points are clustered at a corner and most of the regression line is influenced by only a few data points. The regression line doesn't fit the trend for most of the points. So, we need to shrink the very high values, so that they are closer to the data, and we get model that explains the trend in most of the data.

### 
Plot the transformed model developed in the previous question over a scatterplot of `mortality` vs the transformed income. Did the fit improve?

*(2 + 1 = 3 points)*

### 
Use Box-Cox to identify the appropriate transformation for `mortality` in the transformed model. Write the equation of the transformed model, and report the updated $R^2$

*(3 points)*

### 

Plot the transformed model developed in the previous question over a scatterplot of the transformed `mortality` vs the transformed income. Did the fit improve further?

*(2 + 1 = 3 points)*

### 
Plot the transformed model over the scatterplot of  `mortality` vs `income`.

*(3 points)*

### 

Are there outlying observations in the data with respect to the transformed model developed in the previous question? If not, then how did they disappear given that there were outliers in the model developed in the first question?

*(1 + 3 = 4 points)*

## 
Suppose the error terms in the following linear regression model are independent $N(0, \sigma^2)$:

$Y_i = \beta_0 + \beta_1X_i + \epsilon_i, \epsilon_i \sim N(0, \sigma^2)$.

### 

If $X_i$ is transformed to $X_i'=1/X_i$, then will the error terms still be independent $N(0, \sigma^2)$? If not, then what will change regarding their distribution?

*(4 points)*

###

Instead of $X_i$, if $Y_i$ is transformed to $Y_i'=1/Y_i$, then will the error terms still be independent $N(0, \sigma^2)$? If not, then what will change regarding their distribution?

*(4 points)*

## 

A simple linear regression model with intercept $\beta_0 = 0$ is under consideration. Data have been obtained that contain replications. State the full and reduced models for testing the appropriateness of the regression function under consideration. What are the degrees of freedom associated with the full and reduced model if number of observations $n=20$ and number of distinct values of the predictor $c=10$?

*(2 + 2 = 4 points)*

## 

Let the observed value of the response variable for the $i^{th}$ replicate of the $j^{th}$ level of the predictor $X$ be $Y_{ij}$, where $i=1,...,n_j$, $j= 1,...,c$. Let the number of replica

The fitted regression model is:

$\hat{Y}_{ij} = \hat{\beta}_0+\hat{\beta}_1X_j$

The error deviation can be decomposed as the pure error deviation, and the lack of fit deviation as follows:

$Y_{ij}-\hat{Y}_{ij} = (Y_{ij}-\bar{Y}_j) + (\bar{Y}_j-\hat{Y}_{ij})$

Given the above equation, show that:

$\sum_{i=1}^n_j\sum_{j=1}^c(Y_{ij}-\hat{Y}_{ij})^2 = \sum_{i=1}^n_j\sum_{j=1}^c(Y_{ij}-\bar{Y}_j)^2 + \sum_{i=1}^n_j\sum_{j=1}^c(\bar{Y}_j-\hat{Y}_{ij})^2$.

*(6 points)*