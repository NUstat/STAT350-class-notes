[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Regression analysis (R notes)",
    "section": "",
    "text": "Preface\nThese are coding notes for the course STAT350. If you don’t have a background in R, please use the course material on R from the STAT201 course here: https://nustat.github.io/Intro_to_programming_for_data_sci/Variable_expressions_statements-R.html"
  },
  {
    "objectID": "Rintro.html#installing-r",
    "href": "Rintro.html#installing-r",
    "title": "1  R: Introduction",
    "section": "1.1 Installing R",
    "text": "1.1 Installing R\nGo to the The Comprehensive R Archive Network (CRAN)\n\n\n\nCRAN\n\n\nUnder “Download and Install R,” choose “Linux,” “MacOS X” or “Windows.” If you choose Windows, on the next page choose “base,” and on the following page choose “Download R 4.3.1 for Windows” to download the setup program.\nIf you choose MacOS X or Linux you will need to read through the instructions to find the downloads you need for your machine.\nOnce you have downloaded the setup program, execute it and follow the instructions for installing R on your system. If you have an earlier version of R already installed, you may continue to use it, or you can uninstall it and then install the most recent version, which is R 4.3.1."
  },
  {
    "objectID": "Rintro.html#installing-rstudio",
    "href": "Rintro.html#installing-rstudio",
    "title": "1  R: Introduction",
    "section": "1.2 Installing RStudio",
    "text": "1.2 Installing RStudio\nhttps://rstudio.com/products/rstudio/download/\nChoose your version: RStudio Desktop, Open Source License, Free. It is strongly recommended that you use the latest release of RStudio (v2023.06). After you install RStudio, you can double click on it and open:\n\n\n\nR Studio\n\n\nUsually you will want to import data from a file corresponding to data associated with a homework problem. Such a file will usually end with the extensions *.txt or *.dat. The data files for this course will always be available on the CD that comes with the text and/or on the course web page. A data file will consist of columns of numbers, with nothing separating the columns but “white space.” If each column has a title on top describing what the data in the column represents (e.g., age, weight, income, etc.), we will say that the file has a header."
  },
  {
    "objectID": "Rintro.html#working-directory",
    "href": "Rintro.html#working-directory",
    "title": "1  R: Introduction",
    "section": "1.3 Working directory",
    "text": "1.3 Working directory\nThe easiest way to import the data into R and have it readily available for the current and future sessions is to first save the data file into your working directory. For example mine is C:\\stat350.\nTo set up the working directory, select the project option by choosing File menu, then New Project, and then Create Project from Existing Directory.\nTo start writing a new R script, navigate to the New File option in the File menu, and select Quarto Document. This will create a *.qmd file. You can write both code and formatted-text in this document. When working on assignment / exam problems, you will work on the *.qmd file, render it as HTML and then submit. You can view some examples on how to write R code and text in a *.qmd file and render it as HTML here.\nFor rough work, i.e., work that won’t be graded, you may use the R script option to write code."
  },
  {
    "objectID": "Rintro.html#getting-started-with-code",
    "href": "Rintro.html#getting-started-with-code",
    "title": "1  R: Introduction",
    "section": "1.4 Getting started with code",
    "text": "1.4 Getting started with code\n\n1.4.1 Reading data\nSuppose you want to work with the data from Problem 19 of Chapter 1, which is in a file named CH01PR19.txt which you have saved from the CD or the course web page in the Datasets folder within your R working directory. Assume the file has no header. You will want to create a Table object in R containing this data. First choose an appropriate name for the table. Assume you choose to name it Data. Then, you can execute the following code :\n\nData &lt;- read.table(\"./Datasets/CH01PR19.txt\")\n\nThen there will be a Table object in R named Data containing the data in rows and columns. To view it, you would type\n\nData\n\nHowever, if it is a large file, you might not be able to view the whole table at once. In that case, you may use the head() function, which will display only the first 6 rows of Data:\n\nhead(Data)\n\n     V1 V2\n1 3.897 21\n2 3.885 14\n3 3.778 28\n4 2.540 22\n5 3.028 21\n6 3.865 31\n\n\nNote that, in the absence of a header, the columns will be named V1, V2, etc., and the rows will be numbered.\nNow if the file does have a header (which you may have added yourself), you need to change the above command to:\n\nData &lt;- read.table(\"CH01PR19.txt\", header=TRUE)\n\nIn this case, when you view the file you will see the title for each column at the top of each column instead of V1, V2, etc. R regards these titles as names for the columns, and not as data.\nIf you want to load the data file from some other directory, you need to type the full path name in the read.table() command. For instance,\n\nData &lt;- read.table(file=\"C:/stat350/CH01PR19.txt\", header=FALSE) \n\nYou may read data manually as well. Here both Return and New are vectors.\n\nReturn &lt;- c(74,66,81,52,73,62,52,45,62,46,60,46,38)\nNew &lt;-c(5,6,8,11,12,15,16,17,18,18,19,20,20)\n\n\n\n1.4.2 Renaming columns\nNow suppose the file Data has two columns, and the first column is the GPA, while the second column is ACT score. If you would like to rename the columns in your R data table so that each column has a descriptive title, you could give the R command:\n\nnames(Data) &lt;- c(\"GPA\", \"ACT\")\n\nThen when you view the file the titles of the columns will have the new names you assigned:\n\nhead(Data)\n\n    GPA ACT\n1 3.897  21\n2 3.885  14\n3 3.778  28\n4 2.540  22\n5 3.028  21\n6 3.865  31\n\n\nNote that you can also give the columns these titles in the data file before you load it into R, and then use the header = TRUE setting when loading. Also, to avoid errors, you should never include a space in the title of any column\n\n\n1.4.3 Exporting data\nSuppose you wish to export Data to file Intro.csv in your folder.\n\nwrite.table(Data, \"C:/stat350/Intro.csv\", col.names=TRUE, sep=\",\")\n\nSuppose you wish to export Data to Intro.txt with a tab delimiter:\n\nwrite.table(Data, \"C:/stat350/Intro.txt\", col.names=TRUE, sep=\"\\t\")\n\nYou may export R objects to other file types in a similar manner.\n\n\n1.4.4 R environment\nIf you want to see which R objects are currently in your R environment, you can type:\n\nls()\n\nYou may also see these objects at the top right corner of the R Studio interface.\nIf you no longer need one or more of these objects, you can remove them. For instance, if you are done with Data, you can type:\n\nrm(Data)\n\nThen Data will no longer be in your current R environment. When you quit R, if you wish to keep all the new objects in your current R environment, be sure to answer Yes when asked, Save workspace image?\n\n\n1.4.5 Scatter plots and simple linear regression\nSuppose the data for Problem 19 of Chapter One has been stored in an R object named Data which has two columns, the first column named GPA and the second column named ACT. You want to make a scatterplot in R with ACT scores on the horizontal axis and GPA on the vertical axis. The R command is:\n\nplot(Data$ACT, Data$GPA)\n\n\n\n\nNote that the dollar sign is used to reference either column in the table named Data. The first argument to the plot() function is the column corresponding to the variable associated with the horizontal axis, and the second argument is the column corresponding to the variable associated with the vertical axis. Alternately, you could define two new vector variables, X and Y, to hold the data of the individual columns, and use these vectors as the arguments to the plot() function:\n\nX &lt;- Data$ACT\nY &lt;- Data$GPA\nplot(X, Y)\n\nFor now we will stick with the former approach. The resulting plot appears in the R Graphics Device within the R interface. Click on it to view it, save it, print it, etc.\nNote that whenever you make a new plot the old one will disappear (this can be changed; but not easily), so save it if you don’t want to lose it. However, the current scatterplot is inadequate. It has no title, the axis labels aren’t very informative, and the points are open circles rather than dark filled-in circles. To fix this, we can add some additional settings to the plot() command:\n\nplot(Data$ACT, Data$GPA, main=\"Problem 1.19\", xlab=\"ACT Test Score\", ylab=\"Freshman GPA\", pch=19)\n\n\n\n\nNow we obtain a much nicer scatterplot.\nWhatever you put in quotes after main = will be the title for the plot. Whatever you put in quotes after xlab = and ylab = will the the labels for the horizontal and vertical axes, respectively. The number after pch = is a code for the symbol to use for the points. You can try other numbers from 1 to 25. You can also use any symbol on your keyboard for the points, including numerals and letters, using quotes. For instance, if you want to use an asterisk for the points, type pch=\"*\".\nYou may want to also add a plot of the estimated regression function to the scatterplot of the data. This assumes you have already obtained the least squares estimates of the regression coefficients (see “Simple Linear Regression in R”).\n\nfit &lt;- lm(Data$GPA ~ Data$ACT)\nfit &lt;- lm(GPA~ACT, data=Data)   # another option\nplot(Data$ACT, Data$GPA, main=\"Problem 1.19\", xlab=\"ACT Test Score\", ylab=\"Freshman GPA\", pch=19)\nabline(fit, col = \"red\", lwd = 2) #lwd is for line-width\n\n\n\n\nThe line will appear superimposed over the data. You can also just type the actual values for the estimated intercept and slope if you prefer.\nYou may also use ggplot2 to make plots if you wish. ggplot() has a more intuitive syntax as it is based on the Grammar of Graphics, and also has more comprehensive formatting options.\n\nlibrary(ggplot2)\nggplot(Data, aes(x = ACT, y = GPA))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n  labs(\n    title = \"Problem 1.19\"\n  )\n\n$title\n[1] \"Problem 1.19\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nTo save your plot, click anywhere on the plot, then on the menu bar choose File, then Save as. Choose the format in which you want to save the plot, then where you want to save it on your drive.\nCheck the estimates for the intercept and slope:\n\nfit\n\n\nCall:\nlm(formula = GPA ~ ACT, data = Data)\n\nCoefficients:\n(Intercept)          ACT  \n    2.11405      0.03883  \n\n\nCompute fitted values:\n\nfit$fitted.values \n\nCompute residuals:\n\nfit$residuals\n\nCompute the estimate of \\(\\sigma^2\\), that is, the MSE:\n\nn &lt;- dim(Data)[1]\nsum(fit$residuals^2)/(n-2)\n\n[1] 0.3882848"
  },
  {
    "objectID": "Rintro.html#formatting-.qmd-file",
    "href": "Rintro.html#formatting-.qmd-file",
    "title": "1  R: Introduction",
    "section": "1.5 Formatting *.qmd file:",
    "text": "1.5 Formatting *.qmd file:\nBefore Quarto, *.Rmd files were commonly used to render HTML files with R code and formatted-text. This Cheatsheet is for formatting *.Rmd files. However, you may use it to format *.qmd files as well."
  },
  {
    "objectID": "Rintro.html#some-references-about-using-r",
    "href": "Rintro.html#some-references-about-using-r",
    "title": "1  R: Introduction",
    "section": "1.6 Some references about using R:",
    "text": "1.6 Some references about using R:\n\n100 page Introduction to R from the R website http://www.ics.uci.edu/~jutts/st108/R-intro.pdf\nPractical Regression and Anova using R, by Julian Faraway http://cran.r-project.org/doc/contrib/Faraway-PRA.pdf\nR code by Bryan Goodrich for Kutner et al., Applied Linear Statistical Models 5th ed: https://rpubs.com/bryangoodrich"
  },
  {
    "objectID": "t_test_example.html#question",
    "href": "t_test_example.html#question",
    "title": "2  Hypothesis testing example",
    "section": "2.1 Question",
    "text": "2.1 Question\nCola manufacturers want to test how much the sweetness of a new cola drink is affected by storage. The sweetness loss due to storage was evaluated by 10 professional tasters (by comparing the sweetness before and after storage):\nTaster          Sweetness loss\n\n 1         2.0\n 2         0.4\n 3         0.7  \n 4         2.0  \n 5       −0.4   \n 6         2.2  \n 7       −1.3   \n 8         1.2  \n 9         1.1\n10         2.3\nObviously, we want to test if storage results in a loss of sweetness\nLet \\(\\mu\\) denote the sweetness loss, thus:\nNull hypothesis: \\(H_0: \\mu = 0\\)\nAlternate hypothesis: \\(H_a: \\mu &gt; 0\\)"
  },
  {
    "objectID": "t_test_example.html#solution",
    "href": "t_test_example.html#solution",
    "title": "2  Hypothesis testing example",
    "section": "2.2 Solution",
    "text": "2.2 Solution\nSample mean (\\(\\bar{x}\\)):\n\ndata &lt;- c(2, 0.4, 0.7, 2, -0.4, 2.2, -1.3, 1.2, 1.1, 2.3)\n\nxbar &lt;- mean(data)\nxbar\n\n[1] 1.02\n\n\nT-statistic:\n\nt = xbar/(sd(data)/sqrt(10))\nt\n\n[1] 2.696689\n\n\np-value:\n\n1-pt(t, df = 9)\n\n[1] 0.01226316\n\n\nIf the probability of Type I error considered is 5%, then we reject the null hypothesis, and conclude that the sweetness loss is indeed greater than 0.\nIf the probability of Type I error considered is 1%, then we fail to reject the null hypothesis, and conclude that the sweetness loss is indeed 0."
  },
  {
    "objectID": "Assignment A.html#instructions",
    "href": "Assignment A.html#instructions",
    "title": "Appendix A — Assignment A",
    "section": "Instructions",
    "text": "Instructions\n\nYou may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.\nMake R code chunks to insert code and type your answer outside the code chunks. Ensure that the solution is written neatly enough to understand and grade.\nRender the file as HTML to submit. For theoretical questions, you can either type the answer and include the solutions in this file, or write the solution on paper, scan and submit separately.\nThe assignment is worth 100 points, and is due on 7th October 2023 at 11:59 pm.\nFive points are properly formatting the assignment. The breakdown is as follows:\n\n\nMust be an HTML file rendered using Quarto (the theory part may be scanned and submitted separately) (2 pts).\nThere aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.). There is no piece of unnecessary / redundant code, and no unnecessary / redundant text (1 pt)\nFinal answers of each question are written clearly (1 pt).\nThe proofs are legible, and clearly written with reasoning provided for every step. They are easy to follow and understand (1 pt)"
  },
  {
    "objectID": "Assignment A.html#section",
    "href": "Assignment A.html#section",
    "title": "Appendix A — Assignment A",
    "section": "A.1 ",
    "text": "A.1 \nThe first step in using the capital asset pricing model (CAPM) is to estimate the stock’s beta \\((\\beta)\\) using the market model. The market model can be written as:\n\\(R_{it} = \\alpha_i + \\beta_iR_{mt} + \\epsilon_{it},\\)\nwhere \\(R_{it}\\) is the excess return for security \\(i\\) at time \\(t\\), \\(R_{mt}\\) is the excess return on a proxy for the market portfolio at time \\(t\\), and \\(\\epsilon_t\\) is an iid random disturbance term. The coefficient beta in this case is the CAPM beta for security \\(i\\).\nSuppose that you had estimated \\(\\beta\\) for a stock as \\(\\hat{\\beta}=1.147\\). The standard error associated with this coefficient \\(SE(\\hat{\\beta})\\) is estimated to be 0.0548. A city analyst has told you that this security closely follows the market, but that it is no more risky, on average, than the market. This can be tested by the null hypotheses that the value of beta \\((\\beta)\\) is one. The model is estimated over 62 daily observations. Test this hypothesis against a one-sided alternative that the security is more risky than the market \\((\\beta&gt;1)\\). Consider Type 1 error \\((\\alpha)\\) as \\(1\\%\\). Write down the null and alternative hypothesis. What do you conclude?\nDoes your conclusion change if you consider the Type 1 error \\((\\alpha)\\) as \\(0.1\\%\\)?\n(4 + 1 = 5 points)"
  },
  {
    "objectID": "Assignment A.html#section-1",
    "href": "Assignment A.html#section-1",
    "title": "Appendix A — Assignment A",
    "section": "A.2 ",
    "text": "A.2 \nWhen asked to state the simple linear regression model, a students wrote it as follows: \\(E(Y_i) = \\beta_0 + \\beta_1X_1 + \\epsilon_i\\). Is this correct? Justify your answer.\n(2 points)"
  },
  {
    "objectID": "Assignment A.html#section-2",
    "href": "Assignment A.html#section-2",
    "title": "Appendix A — Assignment A",
    "section": "A.3 ",
    "text": "A.3 \nConsider the simple linear regression model below:\n\\(Y_i = \\beta_0 + \\beta_1X_1 + \\epsilon_i, i = 1,...,n\\)\nwhere:\n\\(\\beta_0 = 100, \\beta_1 = 20,\\) and \\(\\sigma^2 =5\\). The following assumptions are made for the model:\nA. \\(E(\\epsilon_i) = 0,\\)\nB. \\(Var(\\epsilon_i) = \\sigma^2,\\)\nC. \\(Cov(\\epsilon_i, \\epsilon_j)=0 \\ \\forall i, j; i\\ne j\\)\nAn observation \\(Y\\) is made for \\(X=5\\)\nCan you state the exact probability that \\(Y\\) will fall between 195 and 205? If yes, then compute the probability. If not, then state any reasonable assumption(s) you need to make to compute the probability, and then compute the probability.\n(1 + 1 + 4 = 6 points)"
  },
  {
    "objectID": "Assignment A.html#section-3",
    "href": "Assignment A.html#section-3",
    "title": "Appendix A — Assignment A",
    "section": "A.4 ",
    "text": "A.4 \nThe Toluca Company manufactures refrigeration equipment in lots of varying sizes. The dataset toluca.txt consists of of two columns - LotSize and WorkHours required to produce the lot.\nWhen asked for a point estimate of the expected work hours for lot sizes of 30 pieces, a person gave the estimate 202 because that is the mean number of WorkHours for the three observations of LotSize = 30 pieces in the dataset. Is there an issue with this approach? Explain. If there is an issue, then suggest a better approach and use it to estimate the expected work hours for lot sizes of 30 pieces.\n(2 + 2 + 4 = 8 points)"
  },
  {
    "objectID": "Assignment A.html#section-4",
    "href": "Assignment A.html#section-4",
    "title": "Appendix A — Assignment A",
    "section": "A.5 ",
    "text": "A.5 \nConsider the simple linear regression model below:\n\\(\\log(Y)=\\beta_0+\\beta_1\\log(X)+\\epsilon\\)\nInterpret the coefficient \\(\\beta_1\\), where you mention the approximate expected percentage increase in \\(Y\\) given an increase of \\(1\\%\\) in \\(X\\).\nUse the approximation: \\(\\log(1+x) = x\\) if \\(x&lt;&lt;1\\)\n(5 points)"
  },
  {
    "objectID": "Assignment A.html#section-5",
    "href": "Assignment A.html#section-5",
    "title": "Appendix A — Assignment A",
    "section": "A.6 ",
    "text": "A.6 \nThe dataset ACT_GPA consists of the GPA at the end of freshmen year (\\(Y\\)) that can be predicted from the ACT score (\\(X\\)) of students of a college.\n\nA.6.1 \nObtain the least square estimates of the regression coefficients, and error standard deviation, and state the estimated regression function.\n(5 points)\n\n\nA.6.2 \nObtain the maximum likelihood estimate of the error standard deviation. Is it the same as that obtained in the previous question? Why or why not? If it isn’t same, which estimate will you prefer - the MLE or the one obtained in the previous question and why?\n(2 + 2 + 4 = 8 points)\n\n\nA.6.3 \nInterpret the estimates of the regression coefficients and the error standard deviation as obtained in A.6.1. What is the increase in expected GPA for an increase of 2 points in the ACT score?\n(6 + 2 = 8 points)\n\n\nA.6.4 \nDoes ACT have a statistically significant relationship with the GPA? Justify your answer.\n(1 + 2 = 3 points)\n\n\nA.6.5 \nPlot the estimated regression function and the data. Does the estimated regression function appear to fit the data well?\n(3 + 1 = 4 points)\n\n\nA.6.6 \nInclude the 95% confidence and prediction intervals in the above plot.\n(6 points)\n\n\nA.6.7 \nObtain a point estimate, and the 95% confidence and prediction intervals of the freshman GPA for students with an ACT score of \\(30\\).\n(1 + 2 + 2 = 5 points)\n\n\nA.6.8 \nThe intercept of the model developed in Q4(a) is the expected GPA when the ACT score is zero. However, the ACT score can never be zero as the minimum possible ACT score is 1 (ref). So, should the intercept be removed from the model? Why or why not?\n(2 + 4 = 6 points)"
  },
  {
    "objectID": "Assignment A.html#section-14",
    "href": "Assignment A.html#section-14",
    "title": "Appendix A — Assignment A",
    "section": "A.7 ",
    "text": "A.7 \nConsider the regression model in A.3, where the parameters are estimated using Maximum likelihood estimation. Let \\(e_i\\) denote the \\(i^{th}\\) residual. Prove that:\n\n\\(\\sum_{i = 1}^n \\hat{Y}_ie_i = 0\\)\n\\(\\sum_{i=1}^n Y_i = \\sum_{i=1}^n \\hat{Y}_i\\)\nThe regression line passes through the point (\\(\\bar{X}, \\bar{Y}\\))\n\n(3 + 3 + 3 = 9 points)"
  },
  {
    "objectID": "Assignment A.html#section-15",
    "href": "Assignment A.html#section-15",
    "title": "Appendix A — Assignment A",
    "section": "A.8 ",
    "text": "A.8 \nConsider the regression model:\n\\(Y_i = \\beta_0 + \\epsilon_i, i = 1,...,n\\), where \\(\\epsilon \\sim N(0, \\sigma^2)\\)\nDerive the maximum likelihood estimate of \\(\\beta_0\\), and show whether it is a biased or unbiased estimate of \\(\\beta_0\\).\n(3 + 3 = 6 points)"
  },
  {
    "objectID": "Assignment A.html#section-16",
    "href": "Assignment A.html#section-16",
    "title": "Appendix A — Assignment A",
    "section": "A.9 ",
    "text": "A.9 \nConsider the regression model:\n\\(Y_i = \\beta_1X_i + \\epsilon_i, i = 1,...,n\\), where \\(\\epsilon \\sim N(0, \\sigma^2)\\)\nDerive the maximum likelihood estimate of \\(\\beta_1\\), and show whether it is a biased or unbiased estimate of \\(\\beta_1\\).\n(4 + 5 = 9 points)"
  },
  {
    "objectID": "Assignment B.html#instructions",
    "href": "Assignment B.html#instructions",
    "title": "Appendix B — Assignment B",
    "section": "Instructions",
    "text": "Instructions\n\nYou may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.\nMake R code chunks to insert code and type your answer outside the code chunks. Ensure that the solution is written neatly enough to understand and grade.\nRender the file as HTML to submit. For theoretical questions, you can either type the answer and include the solutions in this file, or write the solution on paper, scan and submit separately.\nThe assignment is worth 100 points, and is due on 14th October 2023 at 11:59 pm.\nFive points are properly formatting the assignment. The breakdown is as follows:\n\n\nMust be an HTML file rendered using Quarto (the theory part may be scanned and submitted separately) (2 pts).\nThere aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.). There is no piece of unnecessary / redundant code, and no unnecessary / redundant text (1 pt)\nFinal answers of each question are written clearly (1 pt).\nThe proofs are legible, and clearly written with reasoning provided for every step. They are easy to follow and understand (1 pt)\n\nAll question are based on the normal linear regression model below, unless otherwise stated:\n\\(Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i, i = 1,...,n\\), where \\(\\epsilon \\sim N(0, \\sigma^2)...(1)\\)"
  },
  {
    "objectID": "Assignment B.html#section",
    "href": "Assignment B.html#section",
    "title": "Appendix B — Assignment B",
    "section": "B.1 ",
    "text": "B.1 \nThe dataset crime.txt consists of number of crimes per 100,000 residents and percentage of individuals having high school diploma in 84 counties.\n\nB.1.1 \nEstimate the expected decrease in number of crimes per 100,000 residents when the proportion of individuals having high school diploma increases by 1%. Use a 99% confidence interval. Interpret the interval estimate.\n(4 + 2 = 6 points)\n\n\nB.1.2 \nFor what percentage of individuals having a high school diploma in a county will you be the most confident in estimating the crime rate with a confidence interval of a given width?\n(2 points)\n\n\nB.1.3 \nFor what range of values of the percentage of individuals having a high school diploma in a county will it be inappropriate to use the developed model (in B.1.1) to predict the crime rate?\n(2 points)\n\n\nB.1.4 \nPredict the number of crimes per 100,000 residents of a county using a 90% prediction interval if 75% of the individuals have a high school diploma in the county. Interpret the prediction interval.\n(2 + 2 = 4 points)\n\n\nB.1.5 \nA consultant had stated that the expected number of crimes per 100,000 should reduce by at least 1000 for a 4% increase in the proportion of people having high school diplomas. Conduct a hypothesis test to verify the statement. Consider the probability of type 1 error as 5%. State the null and alternate hypotheses, p-value, and conclusion from the test.\n(2 + 2 + 2 = 6 points)\n\n\nB.1.6 \nWhat is the probability that you will reject the null hypothesis in the previous question if it is actually false, and the true value of \\(\\beta_1\\) is \\(\\beta_1 = -200\\).\n(7 points)\n\n\nB.1.7 \nBy how much is the total variation in crime rate reduced when percentage of high school graduates is introduced into the analysis?\n(2 points)"
  },
  {
    "objectID": "Assignment B.html#section-8",
    "href": "Assignment B.html#section-8",
    "title": "Appendix B — Assignment B",
    "section": "B.2 ",
    "text": "B.2 \nSuppose that the normal error regression model is applicable except that the error variance is not constant; rather the variance is larger, the larger is \\(X\\). Does \\(\\beta_1=0\\) still imply that there is no linear association between \\(X\\) and \\(Y\\)? Explain.\nDoes it also imply that there is no association between \\(X\\) and \\(Y\\)? Or, does it also imply that there is an association between \\(X\\) and \\(Y\\)? Explain.\n(2 + 2 + 2 = 6 points)"
  },
  {
    "objectID": "Assignment B.html#section-9",
    "href": "Assignment B.html#section-9",
    "title": "Appendix B — Assignment B",
    "section": "B.3 ",
    "text": "B.3 \nShow that the regression sum of squares has only one degree of freedom for model (1). You may use the normal equations obtained from minimizing of sum of squared errors.\n(4 points)"
  },
  {
    "objectID": "Assignment B.html#section-10",
    "href": "Assignment B.html#section-10",
    "title": "Appendix B — Assignment B",
    "section": "B.4 ",
    "text": "B.4 \nIn a small-scale regression study, five observations on \\(Y\\) were obtained corresponding to \\(X=1, 4, 10, 11,\\) and \\(14\\). Assume that \\(\\sigma = 0.6, \\beta_0 = 5,\\) and \\(\\beta_1=3\\).\n\nB.4.1 \nWhat are the expected values of MSR and MSE?\n(3 + 2 = 5 points)\n\n\nB.4.2 \nFor determining whether or not a regression relation exists, would it have been better or worse to have made the five observations at \\(X=6,7,8,9,10\\)? Why? Would the same answer apply if the principal purpose were to estimate the mean response for \\(X=8\\). Explain.\n(3 + 3 = 6 points)"
  },
  {
    "objectID": "Assignment B.html#section-13",
    "href": "Assignment B.html#section-13",
    "title": "Appendix B — Assignment B",
    "section": "B.5 ",
    "text": "B.5 \nConsider the following code and its output below.\n\n#Setting seed for reproducibility\nset.seed(10)\n\n#Simulating data\nx &lt;- seq(0, 1, 0.01)\ny &lt;- 0.5 + 2*x + rnorm(length(x))\ndata &lt;- data.frame(x = x, y = y)\n\n#Developing linear regression model\nmodel &lt;- lm(y~x, data = data)\nsummary(model)\n\n\nCall:\nlm(formula = y ~ x, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.8866 -0.6294  0.0103  0.6819  2.2644 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.08838    0.18370   0.481    0.631    \nx            2.53776    0.31738   7.996 2.45e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9299 on 99 degrees of freedom\nMultiple R-squared:  0.3924,    Adjusted R-squared:  0.3863 \nF-statistic: 63.94 on 1 and 99 DF,  p-value: 2.448e-12\n\n\nWe see that the intercept is statistically insignificant. As it is insignificant, a student suggested that it won’t matter if it is removed from the developed model, i.e., if the developed model is changed to:\n\\(Y_i = \\beta_1X_i + \\epsilon_i, i = 1,...,n\\), where \\(\\epsilon \\sim N(0, \\sigma^2) ... (2)\\)\n\nB.5.1 \nGiven that \\(\\beta_0 \\ne 0\\), derive the expression for the bias in the estimate of \\(\\beta_1\\) if model (2) is considered.\n(4 points)\n\n\nB.5.2 \nUse the simulated data to compute the value of the bias obtained from the expression derived in the previous question (B.5.1).\n(2 points)\n\n\nB.5.3 \nUse simulations to verify the value of bias computed in the previous question (B.5.2). Simulate the data 1000 times. Set a unique value of seed to generate a unique dataset in every iteration. In each iteration, estimate \\(\\beta_1\\). Report the bias in the estimate of \\(\\beta_1\\) based on the 1000 simulations. Is it the same as obtained analytically in the previous question (B.5.2)?\nNote that: \\(Bias(\\hat{\\beta}_1) = E(\\hat{\\beta}_1 - \\beta_1)\\)\n(5 + 1 = 6 points)\n\n\nB.5.4 \nPlot the 1000 regression lines based on the 1000 coefficient estimates of the no-intercept model (as obtained in B.5.3) over a scatterplot of the data points.\n(2 points)\n\n\nB.5.5 \nNow consider the simple linear regression model with the intercept (model 1). Simulate the data 1000 times. In each iteration, estimate \\(\\beta_1\\). Report the bias in the estimate of \\(\\beta_1\\) based on the 1000 simulations.\n(4 points)\n\n\nB.5.6 \nPlot the 1000 regression lines based on the 1000 coefficient estimates of the model with intercept (as obtained in B.5.5) over a scatterplot of the data points.\n(2 points)\n\n\nB.5.7 \nBased on the simulations and analytical results, answer the following:\n\nB.5.7.1 \nIf the intercept is found to be statistically insignificant in model (1) as shown in the model summary, should it be removed from the model, and model (1) considered instead? Explain.\n(3 points)\n\n\nB.5.7.2 \nSuppose we know that the true model passes through the origin \\((X = 0, Y = 0)\\). Should we consider model (1) or model (2) in this case? Explain.\n(2 points)\n\n\n\nB.5.8 \nIn terms of bias and variance, mention an advantage and a disadvantage of the estimate of \\(\\beta_1\\) from model (2) as compared to that obtained from model (1), if \\(\\beta_0 \\ne 0\\). The plots developed in earlier questions may also help visualize the advantage and disadvantage.\n(2 + 2 = 4 points)"
  },
  {
    "objectID": "Assignment B.html#section-24",
    "href": "Assignment B.html#section-24",
    "title": "Appendix B — Assignment B",
    "section": "B.6 ",
    "text": "B.6 \nProve that the estimate of the intercept \\(\\beta_0\\), i.e., \\(\\hat{\\beta}_0\\) for model (1) has minimum variance among all unbiased linear estimators.\n(5 points)"
  },
  {
    "objectID": "Assignment B.html#section-25",
    "href": "Assignment B.html#section-25",
    "title": "Appendix B — Assignment B",
    "section": "B.7 ",
    "text": "B.7 \nDerive the variance of the estimators obtained in questions A.8 and A.9 of Assignment A.\n(2 + 2 = 4 points)"
  },
  {
    "objectID": "Assignment B.html#section-26",
    "href": "Assignment B.html#section-26",
    "title": "Appendix B — Assignment B",
    "section": "B.8 ",
    "text": "B.8 \nSuppose the true value of \\(\\beta_0\\) is known, while that of \\(\\beta_1\\) is unknown and needs to be estimated. The stakeholder wishes to choose the model (from model (1) and model(2)), such that the expected squared error in the estimate of \\(\\beta_1\\), is the minimum, i.e., they wish to select the model that has a lesser value of \\(E(\\hat{\\beta}_1 - \\beta_1)^2\\). Derive the condition (based on the value \\(\\beta_0\\)), which if true will imply that model (2) should be chosen instead of model (1).\nHint:\n\\(E(X^2) = [E(X)]^2 + Var(X)\\)\n\\(\\implies E(\\hat{\\beta}_1 - \\beta_1)^2 = [E(\\hat{\\beta}_1 - \\beta_1)]^2 + Var(\\hat{\\beta}_1 - \\beta_1)\\)\nModel (2) should be selected when \\(E(\\hat{\\beta}_1 - \\beta_1)^2\\) for model (2) is lesser than \\(E(\\hat{\\beta}_1 - \\beta_1)^2\\) for model (1).\n(7 points)"
  },
  {
    "objectID": "Assignment C.html#instructions",
    "href": "Assignment C.html#instructions",
    "title": "Appendix C — Assignment C",
    "section": "Instructions",
    "text": "Instructions\n\nYou may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.\nMake R code chunks to insert code and type your answer outside the code chunks. Ensure that the solution is written neatly enough to understand and grade.\nRender the file as HTML to submit. For theoretical questions, you can either type the answer and include the solutions in this file, or write the solution on paper, scan and submit separately.\nThe assignment is worth 100 points, and is due on 22nd October 2023 at 11:59 pm.\nThere is an extra credit question worth 10 points in the end. You can score 110/100 in the assignment.\nFive points are properly formatting the assignment. The breakdown is as follows:\n\n\nMust be an HTML file rendered using Quarto (the theory part may be scanned and submitted separately) (2 pts).\nThere aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.). There is no piece of unnecessary / redundant code, and no unnecessary / redundant text (1 pt)\nFinal answers of each question are written clearly (1 pt).\nThe proofs are legible, and clearly written with reasoning provided for every step. They are easy to follow and understand (1 pt)"
  },
  {
    "objectID": "Assignment C.html#real-estate-sales",
    "href": "Assignment C.html#real-estate-sales",
    "title": "Appendix C — Assignment C",
    "section": "C.1 Real estate sales",
    "text": "C.1 Real estate sales\nRead the file real_estate_sales.txt.\n\nC.1.1 \nDevelop a linear regression model to predict price of a house based on square_feet (floor area of the house). Check the following model assumptions using diagnostic plots:\n\nLinear relationship\nHomoscedasticity\nNormal distribution of errors\n\nFor each of the above assumption, comment if it is appears to be satisfied or violated based on the plots.\n(2 + 2 + 2 = 6 points)\n\n\nC.1.2 \nConsider performing the statistical test to check the linear relationship assumption. What condition must be satisfied by the data for the test to be performed? Show that the condition is satisfied by this data.\n(1 + 2 = 3 points)\n\n\nC.1.3 \nPerform the statistical test to check the linear relationship assumption. What is your conclusion?\n(2 points)\n\n\nC.1.4 \nCheck assumptions (2) and (3) as mentioned in C.1.1 with statistical tests, and mention your conclusion.\n(2 + 2 = 4 points)\n\n\nC.1.5 \nUse the Box-Cox procedure to identify the appropriate transformation of the regression model developed in C.1.1. Write the transformed model equation.\n(3 + 2 = 5 points)\n\n\nC.1.6 \nCheck all the 3 model assumptions mentioned in C.1.1 for the transformed model developed in C.1.5. Use both diagnostic plots and statistical tests. Mention your comments based on the plots and conclusions based on the tests.\n(2 + 2 + 2 = 6 points)\n\n\nC.1.7 \nIs the transformed model (developed in C.1.5) better than the original model (developed in C.1.1) with respect to the model assumptions? Comment based on the tests/plots in the previous question (C.1.6).\n(2 points)\n\n\nC.1.8 \nIf the linearity assumption is still not satisfied in the transformed model (developed in C.1.5),\n\nPropose another transformation based on the diagnostic plot(s) plotted in the previous question.\nWrite the transformed model equation.\nShow that the transformed model (based on the proposed transformation in (a)) satisfies the linearity assumption based on the statistical test, if the probability of type I error considered is 1%.\nAlso make the diagnostic plot for the transformed model (based on the proposed transformation in (a)) to show that it satisfies the linearity assumption.\n\n(2 + 2 + 2 + 2 = 8 points)\n\n\nC.1.9 \nDoes the transformed model developed in the previous question (C.1.8) satisfy the homoscedasticity and normally distributed errors assumptions? Verify based on diagnostic plots and statistical tests.\n(2 + 2 = 4 points)\n\n\nC.1.10 \nPlot all the three models - the original model (developed in C.1.1), the boxcox transformed model (developed in C.1.5), and the final model (developed in C.1.8) over a scatterplot of price vs square_feet. Which model seems to have the best fit? Also report the \\(R^2\\) of all the 3 models.\n(1 + 3 + 1 + 3 = 8 points)"
  },
  {
    "objectID": "Assignment C.html#mortality-vs-income",
    "href": "Assignment C.html#mortality-vs-income",
    "title": "Appendix C — Assignment C",
    "section": "C.2 Mortality vs Income",
    "text": "C.2 Mortality vs Income\nThe dataset infmort.csv gives the infant mortality of different countries in the world. The column mortality contains the infant mortality in deaths per 1000 births.\n\nC.2.1 \nRead the dataset. There are 4 observations that have missing values. Remove those observations from the dataset.\nHint: You may use the R function complete.cases().\n(2 points)\n\n\nC.2.2 \nOver the scatterplot of mortality against income, plot the regression model predicting mortality based on income. Report the \\(R^2\\) for this model.\n(2 + 1 = 3 points)\n\n\nC.2.3 \nAre there outlying observations in the data with respect to the model developed in the previous question (C.2.2)? How many? Consider observations having a magnitude of standardized residual more than 5 as outliers.\n(2 points)\n\n\nC.2.4 \nBased on the plot in C.2.2, propose a transformation for income. Justify the proposed transformation. Write the equation of the transformed model and report its \\(R^2\\).\n(2 + 2 + 1 + 1 = 6 points)\n\n\nC.2.5 \nPlot the transformed model developed in the previous question over a scatterplot of mortality vs the transformed income (as transformed in the previous question (C.2.4)). Did the model fit of the transformed model (developed in C.2.4) improve over the fit of the original model (developed in C.2.2)?\n(2 + 1 = 3 points)\n\n\nC.2.6 \nUse Box-Cox to identify the appropriate transformation for mortality in the transformed model (developed in C.2.4). Write the equation of the Box-Cox transformed model, and report its \\(R^2\\).\n(3 points)\n\n\nC.2.7 \nPlot the Box-Cox transformed model developed in the previous question (C.2.6) over a scatterplot of the transformed mortality vs the transformed income. Did the fit of the Box-Cox transformed model improve over the fit of the transformed model (developed in C.2.4)?\n(2 + 1 = 3 points)\n\n\nC.2.8 \nPlot the Box-Cox transformed model (developed in C.2.6) over the scatterplot of mortality vs income.\n(3 points)\n\n\nC.2.9 \nAre there outlying observations in the data with respect to the Box-Cox transformed model (developed in C.2.6)? If not, then how did they disappear given that there were outliers in the original model (developed in C.2.2)?\n(1 + 3 = 4 points)"
  },
  {
    "objectID": "Assignment C.html#section-19",
    "href": "Assignment C.html#section-19",
    "title": "Appendix C — Assignment C",
    "section": "C.3 ",
    "text": "C.3 \nSuppose the error terms in the following linear regression model are independent \\(N(0, \\sigma^2)\\):\n\\(Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i, \\epsilon_i \\sim N(0, \\sigma^2)\\).\n\nC.3.1 \nIf \\(X_i\\) is transformed to \\(X_i'=1/X_i\\), then will the error terms still be independent \\(N(0, \\sigma^2)\\)? If not, then what will be the change in their distribution?\n(4 points)\n\n\nC.3.2 \nInstead of \\(X_i\\), if \\(Y_i\\) is transformed to \\(Y_i'=1/Y_i\\), then will the error terms still be independent \\(N(0, \\sigma^2)\\)? If not, then what will be the change in their distribution?\n(4 points)"
  },
  {
    "objectID": "Assignment C.html#section-22",
    "href": "Assignment C.html#section-22",
    "title": "Appendix C — Assignment C",
    "section": "C.4 ",
    "text": "C.4 \nA simple linear regression model with intercept \\(\\beta_0 = 0\\) is under consideration. Data have been obtained that contain replications.\nState the full and reduced models for testing the appropriateness of the regression function under consideration.\nWhat are the degrees of freedom associated with the full and reduced model if number of observations \\(n=20\\) and number of distinct values of the predictor \\(c=10\\)?\n(2 + 2 = 4 points)"
  },
  {
    "objectID": "Assignment C.html#section-23",
    "href": "Assignment C.html#section-23",
    "title": "Appendix C — Assignment C",
    "section": "C.5 ",
    "text": "C.5 \nLet the observed value of the response variable for the \\(i^{th}\\) replicate of the \\(j^{th}\\) level of the predictor \\(X\\) be \\(Y_{ij}\\), where \\(i=1,...,n_j\\), \\(j= 1,...,c\\).\nThe fitted regression model is:\n\\(\\hat{Y}_{ij} = \\hat{\\beta}_0+\\hat{\\beta}_1X_j\\)\nThe error deviation can be decomposed as the pure error deviation, and the lack of fit deviation as follows:\n\\(Y_{ij}-\\hat{Y}_{ij} = (Y_{ij}-\\bar{Y}_j) + (\\bar{Y}_j-\\hat{Y}_{ij})\\)\nGiven the above equation, show that:\n\\(\\sum_{i=1}^{n_j}\\sum_{j=1}^c(Y_{ij}-\\hat{Y}_{ij})^2 = \\sum_{i=1}^{n_j}\\sum_{j=1}^c(Y_{ij}-\\bar{Y}_j)^2 + \\sum_{i=1}^{n_j}\\sum_{j=1}^c(\\bar{Y}_j-\\hat{Y}_{ij})^2\\).\n(6 points)"
  },
  {
    "objectID": "Assignment C.html#bonus-question",
    "href": "Assignment C.html#bonus-question",
    "title": "Appendix C — Assignment C",
    "section": "C.6 Bonus question",
    "text": "C.6 Bonus question\n(This is extra credit question, you are not required to do it)\nFor \\(\\lambda \\ne 0\\), the Box-Cox transformation is given as:\n\\(y_i^{(\\lambda)}=\\frac{y_i^\\lambda-1}{\\lambda}...(1)\\)\nHowever, typically practitioners transform the response as:\n\\(y_i^{(\\lambda)}=y_i^\\lambda...(2)\\).\nWhy is (2) acceptable in general even when (1) is the transformation proposed by George Box and David Cox? In which cases will it be detrimental to use (2) instead of (1), and one must use (1)?\nSupport your arguments with examples based on simulated data to answer this question. You must provide an example when both (1) and (2) are acceptable, and another example when (2) is not effective, and only (1) must be used.\n(10 points)"
  },
  {
    "objectID": "Datasets.html",
    "href": "Datasets.html",
    "title": "Appendix D — Assignment templates and Datasets",
    "section": "",
    "text": "Assignment templates and datasets used in the class notes can be found here"
  }
]